"""
Ahiler Kalkƒ±nma Ajansƒ± KAYSƒ∞S Scraper Module
Ahiler Kalkƒ±nma Ajansƒ±'nƒ±n KAYSƒ∞S sitesinden mevzuat tarama mod√ºl√º
"""
import requests
from bs4 import BeautifulSoup
from typing import List, Dict, Any, Optional, Tuple
import re
import json
import unicodedata

# Streamlit import (opsiyonel - use_streamlit parametresi ile kontrol edilir)
try:
    import streamlit as st
    STREAMLIT_AVAILABLE = True
except ImportError:
    STREAMLIT_AVAILABLE = False


# ============================================================================
# Yardƒ±mcƒ± Fonksiyonlar
# ============================================================================

def normalize_text(text: str) -> str:
    """Metni kar≈üƒ±la≈ütƒ±rma i√ßin normalize eder (b√ºy√ºk/k√º√ß√ºk harf, bo≈üluklar)"""
    if not text:
        return ""
    # K√º√ß√ºk harfe √ßevir, fazla bo≈üluklarƒ± temizle
    normalized = re.sub(r'\s+', ' ', text.lower().strip())
    return normalized


def is_title_similar(title1: str, title2: str) -> bool:
    """ƒ∞ki ba≈ülƒ±ƒüƒ±n benzer olup olmadƒ±ƒüƒ±nƒ± kontrol eder"""
    norm1 = normalize_text(title1)
    norm2 = normalize_text(title2)
    
    # Tam e≈üle≈üme
    if norm1 == norm2:
        return True
    
    # Bir ba≈ülƒ±k diƒüerini i√ßeriyor mu? (en az 20 karakter)
    if len(norm1) >= 20 and len(norm2) >= 20:
        if norm1 in norm2 or norm2 in norm1:
            return True
    
    # Ba≈ülƒ±klarƒ±n ilk 30 karakteri aynƒ± mƒ±? (hƒ±zlƒ± kontrol)
    if len(norm1) >= 30 and len(norm2) >= 30:
        if norm1[:30] == norm2[:30]:
            return True
    
    return False


def turkish_title(text: str) -> str:
    """T√ºrk√ße karakterleri dikkate alarak Title Case'e √ßevirir"""
    if not text:
        return ""
    # Unicode normalizasyonu (iÃá ‚Üí i)
    s = unicodedata.normalize('NFC', text)
    s = s.replace("i\u0307", "i")
    # T√ºrk√ße k√º√ß√ºk harfe √ßevirme
    tmp = s.replace('I', 'ƒ±').replace('ƒ∞', 'i').lower()
    # Yaygƒ±n kelime/ek d√ºzeltmeleri (heuristic)
    tmp = re.sub(r"\bsayili\b", "sayƒ±lƒ±", tmp)
    tmp = re.sub(r"\bsigortalilik\b", "sigortalƒ±lƒ±k", tmp)
    tmp = re.sub(r"\bsigortali\b", "sigortalƒ±", tmp)
    tmp = re.sub(r"\bi≈ülemleri\b", "i≈ülemleri", tmp)
    # Kelime kelime ba≈ü harf b√ºy√ºt
    words = re.split(r'(\s+)', tmp)
    titled_parts = []
    for w in words:
        if not w or w.isspace():
            titled_parts.append(w)
            continue
        first = w[0]
        rest = w[1:]
        if first == 'i':
            first_up = 'ƒ∞'
        elif first == 'ƒ±':
            first_up = 'I'
        else:
            first_up = first.upper()
        titled_parts.append(first_up + rest)
    return ''.join(titled_parts)


def turkish_sentence_case(text: str) -> str:
    """T√ºrk√ße karakterleri dikkate alarak Sentence Case'e √ßevirir (sadece ilk harf b√ºy√ºk)"""
    if not text:
        return ""
    s = unicodedata.normalize('NFC', text)
    s = s.replace("i\u0307", "i")
    s = s.replace('I', 'ƒ±').replace('ƒ∞', 'i').lower()
    s = s.strip()
    if not s:
        return s
    first = s[0]
    rest = s[1:]
    if first == 'i':
        first_up = 'ƒ∞'
    elif first == 'ƒ±':
        first_up = 'I'
    else:
        first_up = first.upper()
    return first_up + rest


# ============================================================================
# API ƒ∞≈ülemleri
# ============================================================================

def get_uploaded_documents(api_base_url: str, access_token: str, use_streamlit: bool = True) -> List[Dict[str, Any]]:
    """API'den y√ºkl√º mevzuatlarƒ± √ßeker (sayfalama ile)"""
    try:
        url = f"{api_base_url.rstrip('/')}/api/admin/documents"
        
        headers = {
            'Authorization': f'Bearer {access_token}',
            'Content-Type': 'application/json',
            'Accept': 'application/json'
        }
        
        all_documents = []
        page = 1
        limit = 100  # API maksimum 100 kabul ediyor
        has_more = True
        
        # Sayfalama ile t√ºm belgeleri √ßek
        while has_more:
            params = {
                'page': page,
                'limit': limit
            }
            
            response = requests.get(url, headers=headers, params=params, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                if result.get('success') and result.get('data'):
                    documents = result['data'].get('documents', [])
                    all_documents.extend(documents)
                    
                    # Pagination bilgisini kontrol et
                    pagination = result['data'].get('pagination', {})
                    has_more = pagination.get('has_next', False)
                    page += 1
                    
                    # G√ºvenlik i√ßin maksimum 50 sayfa (5000 belge) √ßek
                    if page > 50:
                        if use_streamlit and STREAMLIT_AVAILABLE:
                            st.warning("‚ö†Ô∏è √áok fazla belge var. ƒ∞lk 5000 belge √ßekildi.")
                        else:
                            print("‚ö†Ô∏è √áok fazla belge var. ƒ∞lk 5000 belge √ßekildi.")
                        break
                else:
                    has_more = False
            elif response.status_code == 401:
                if use_streamlit and STREAMLIT_AVAILABLE:
                    st.warning("‚ö†Ô∏è Oturum s√ºresi dolmu≈ü. L√ºtfen tekrar giri≈ü yapƒ±n.")
                else:
                    print("‚ö†Ô∏è Oturum s√ºresi dolmu≈ü. L√ºtfen tekrar giri≈ü yapƒ±n.")
                return []
            elif response.status_code == 422:
                try:
                    error_data = response.json()
                    error_msg = error_data.get('error', {}).get('message', 'Bilinmeyen hata')
                    if use_streamlit and STREAMLIT_AVAILABLE:
                        st.warning(f"‚ö†Ô∏è API parametre hatasƒ±: {error_msg}")
                        st.code(error_data, language="json")
                    else:
                        print(f"‚ö†Ô∏è API parametre hatasƒ±: {error_msg}")
                        print(f"Error details: {error_data}")
                except:
                    if use_streamlit and STREAMLIT_AVAILABLE:
                        st.warning(f"‚ö†Ô∏è API'den belgeler √ßekilemedi: HTTP 422 (Unprocessable Entity)")
                        st.code(response.text[:500] if response.text else "Hata mesajƒ± alƒ±namadƒ±", language="text")
                    else:
                        print(f"‚ö†Ô∏è API'den belgeler √ßekilemedi: HTTP 422 (Unprocessable Entity)")
                        print(response.text[:500] if response.text else "Hata mesajƒ± alƒ±namadƒ±")
                return []
            else:
                if use_streamlit and STREAMLIT_AVAILABLE:
                    st.warning(f"‚ö†Ô∏è API'den belgeler √ßekilemedi: HTTP {response.status_code}")
                    if response.text:
                        try:
                            error_data = response.json()
                            st.code(error_data, language="json")
                        except:
                            st.code(response.text[:500], language="text")
                else:
                    print(f"‚ö†Ô∏è API'den belgeler √ßekilemedi: HTTP {response.status_code}")
                    if response.text:
                        print(response.text[:500])
                return []
        
        # Frontend'de status=completed filtresi uygula
        completed_documents = [
            doc for doc in all_documents 
            if doc.get('processing_status') == 'completed'
        ]
        
        return completed_documents
            
    except Exception as e:
        if use_streamlit and STREAMLIT_AVAILABLE:
            st.warning(f"‚ö†Ô∏è API baƒülantƒ± hatasƒ±: {str(e)}")
        else:
            print(f"‚ö†Ô∏è API baƒülantƒ± hatasƒ±: {str(e)}")
        return []


def check_if_document_exists(document_title: str, uploaded_documents: List[Dict[str, Any]]) -> bool:
    """Belge ba≈ülƒ±ƒüƒ±nƒ±n API'de y√ºkl√º olup olmadƒ±ƒüƒ±nƒ± kontrol eder"""
    for doc in uploaded_documents:
        # title, document_title, belge_adi alanlarƒ±nƒ± kontrol et
        doc_titles = [
            doc.get('title', ''),
            doc.get('document_title', ''),
            doc.get('belge_adi', ''),
            doc.get('filename', '')
        ]
        
        for doc_title in doc_titles:
            if doc_title and is_title_similar(document_title, doc_title):
                return True
    
    return False


# ============================================================================
# KAYSƒ∞S Scraping Fonksiyonlarƒ±
# ============================================================================

def scrape_ahiler_kalkinma_ajansi_mevzuat(url: str = "https://kms.kaysis.gov.tr/Home/Kurum/17211906") -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:
    """
    KAYSƒ∞S sitesinden Ahiler Kalkƒ±nma Ajansƒ± mevzuatlarƒ±nƒ± tarar ve API ile kar≈üƒ±la≈ütƒ±rƒ±r
    
    Args:
        url: Taranacak kurum URL'i (varsayƒ±lan: Ahiler Kalkƒ±nma Ajansƒ± KAYSƒ∞S URL'i)
    
    Returns:
        Tuple[List[Dict[str, Any]], Dict[str, Any]]: (all_sections, stats)
            - all_sections: T√ºm b√∂l√ºmler ve mevzuatlar
            - stats: ƒ∞statistikler (toplam b√∂l√ºm, toplam mevzuat, y√ºkl√º sayƒ±sƒ± vb.)
    """
    print(f"üîç Ahiler Kalkƒ±nma Ajansƒ± Mevzuat Tarama Ba≈ülatƒ±lƒ±yor...")
    print(f"üì° Site: {url}")
    
    # Config'den bilgileri y√ºkle
    api_base_url = ''
    access_token = ''
    
    try:
        with open('config.json', 'r', encoding='utf-8') as f:
            config = json.load(f)
            api_base_url = config.get('api_base_url', '')
            email = config.get('admin_email', '')
            password = config.get('admin_password', '')
            
            if api_base_url and email and password:
                print("üîê API'ye baƒülanƒ±lƒ±yor...")
                # Login endpoint
                login_url = f"{api_base_url.rstrip('/')}/api/auth/login"
                login_data = {"email": email, "password": password}
                
                login_response = requests.post(
                    login_url,
                    headers={"Content-Type": "application/json"},
                    json=login_data,
                    timeout=60
                )
                
                if login_response.status_code == 200:
                    result = login_response.json()
                    access_token = result.get("access_token", "")
                    print("‚úÖ API'ye baƒülantƒ± ba≈üarƒ±lƒ±!")
                else:
                    print(f"‚ö†Ô∏è API'ye baƒülanƒ±lamadƒ±: HTTP {login_response.status_code}")
                    print("‚ÑπÔ∏è Mevzuat kar≈üƒ±la≈ütƒ±rmasƒ± yapƒ±lamayacak.")
            else:
                print("‚ö†Ô∏è Config eksik bilgiler i√ßeriyor. Mevzuat kar≈üƒ±la≈ütƒ±rmasƒ± yapƒ±lamayacak.")
    except Exception as e:
        print(f"‚ö†Ô∏è Config y√ºklenemedi: {str(e)}")
        print("‚ÑπÔ∏è Mevzuat kar≈üƒ±la≈ütƒ±rmasƒ± yapƒ±lamayacak.")
    
    print("\nüåê Siteye baƒülanƒ±lƒ±yor...")
    
    try:
        # Siteye istek g√∂nder
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=30)
        
        if response.status_code != 200:
            print(f"‚ùå Siteye eri≈üilemedi: HTTP {response.status_code}")
            return [], {}
        
        # HTML'i parse et
        soup = BeautifulSoup(response.content, 'html.parser')
        print("‚úÖ Site ba≈üarƒ±yla y√ºklendi!")
        
        print("üìã Accordion yapƒ±sƒ± aranƒ±yor...")
        
        # accordion2 div'ini bul
        accordion_div = soup.find('div', {'id': 'accordion2', 'class': 'panel-group'})
        
        if not accordion_div:
            print("‚ö†Ô∏è accordion2 div'i bulunamadƒ±!")
            return [], {}
        
        print("‚úÖ Accordion yapƒ±sƒ± bulundu!")
        print("üîç Ba≈ülƒ±klar ve i√ßerikler √ßekiliyor...")
        
        # Accordion i√ßindeki t√ºm panel'leri bul
        panels = accordion_div.find_all('div', class_='panel')
        
        if not panels:
            panels = accordion_div.find_all(['div'], class_=lambda x: x and 'panel' in str(x).lower())
        
        all_sections = []
        
        if panels:
            for panel in panels:
                # Panel ba≈ülƒ±ƒüƒ±nƒ± bul
                panel_heading = panel.find('div', class_=lambda x: x and 'heading' in str(x).lower())
                if not panel_heading:
                    panel_heading = panel.find(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'a', 'span'], class_=lambda x: x and ('heading' in str(x).lower() or 'title' in str(x).lower()))
                
                heading_text = ""
                if panel_heading:
                    # Ba≈ülƒ±k i√ßindeki badge/span sayacƒ±larƒ±nƒ± √ßƒ±kar
                    try:
                        for badge in panel_heading.find_all('span', class_=lambda c: c and 'badge' in c):
                            badge.decompose()
                    except Exception:
                        pass
                    heading_text = panel_heading.get_text(strip=True)
                    # Sonda kalan sayƒ±larƒ± da temizle (√∂rn: "Kanunlar4" -> "Kanunlar")
                    heading_text = re.sub(r"\d+\s*$", "", heading_text).strip()
                
                # Panel i√ßindeki linkleri ve i√ßerikleri bul
                panel_body = panel.find('div', class_=lambda x: x and 'body' in str(x).lower())
                if not panel_body:
                    panel_body = panel
                
                # Panel i√ßindeki t√ºm linkleri bul
                links_in_panel = panel_body.find_all('a', href=True)
                
                items_in_section = []
                for link in links_in_panel:
                    link_href = link.get('href', '')
                    
                    # Link i√ßinde badge span'i varsa atla
                    if link.find('span', class_='badge'):
                        continue
                    
                    # Link metnini al
                    link_text = link.get_text(strip=True)
                    
                    # Bo≈ü veya √ßok kƒ±sa metinleri atla
                    if not link_text or len(link_text.strip()) < 10:
                        continue
                    
                    # Sadece sayƒ±lardan olu≈üan metinleri atla
                    if re.match(r'^[\d\s.,]+$', link_text.strip()):
                        continue
                    
                    # Link URL'ini tamamla
                    if link_href.startswith('http'):
                        full_url = link_href
                    elif link_href.startswith('/'):
                        full_url = f"https://kms.kaysis.gov.tr{link_href}"
                    else:
                        full_url = f"{url}{link_href}"
                    
                    # Sadece /Home/Goster/ ile ba≈ülayan linkleri al
                    if not full_url or '/Home/Goster/' not in full_url:
                        continue
                    
                    # Metni formatla: yalnƒ±zca ba≈ülƒ±ƒüƒ±n ilk harfi b√ºy√ºk, diƒüerleri k√º√ß√ºk (T√ºrk√ße)
                    formatted_text = turkish_sentence_case(link_text)
                    formatted_text = re.sub(r'\d+$', '', formatted_text).strip()
                    original_text = link_text.strip()
                    
                    items_in_section.append({
                        'baslik': formatted_text,
                        'baslik_original': original_text,
                        'link': full_url
                    })
                
                if heading_text or items_in_section:
                    all_sections.append({
                        'section_title': heading_text or 'Ba≈ülƒ±ksƒ±z B√∂l√ºm',
                        'items': items_in_section
                    })
        
        print(f"‚úÖ {len(all_sections)} b√∂l√ºm bulundu")
        total_items = sum(len(section['items']) for section in all_sections)
        print(f"üìä Toplam {total_items} mevzuat bulundu")
        
        # API'den y√ºkl√º mevzuatlarƒ± √ßek
        uploaded_documents = []
        if api_base_url and access_token:
            print("\nüì° API'den y√ºkl√º mevzuatlar kontrol ediliyor...")
            uploaded_documents = get_uploaded_documents(api_base_url, access_token, use_streamlit=False)
            if uploaded_documents:
                print(f"‚úÖ API'den {len(uploaded_documents)} y√ºkl√º mevzuat bulundu")
            else:
                print("‚ÑπÔ∏è API'de y√ºkl√º mevzuat bulunamadƒ± veya baƒülantƒ± kurulamadƒ±")
        
        # Kar≈üƒ±la≈ütƒ±rma ve istatistikler
        stats = {
            'total_sections': len(all_sections),
            'total_items': total_items,
            'uploaded_documents_count': len(uploaded_documents),
            'sections_stats': []
        }
        
        for section in all_sections:
            section_title = section['section_title']
            items = section['items']
            
            uploaded_count = 0
            not_uploaded_count = 0
            
            for item in items:
                is_uploaded = False
                if uploaded_documents:
                    is_uploaded = check_if_document_exists(item['baslik'], uploaded_documents)
                    if not is_uploaded and item.get('baslik_original'):
                        is_uploaded = check_if_document_exists(item['baslik_original'], uploaded_documents)
                
                if is_uploaded:
                    uploaded_count += 1
                else:
                    not_uploaded_count += 1
            
            stats['sections_stats'].append({
                'section_title': section_title,
                'total': len(items),
                'uploaded': uploaded_count,
                'not_uploaded': not_uploaded_count
            })
        
        return all_sections, stats
        
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Baƒülantƒ± hatasƒ±: {str(e)}")
        return [], {}
    except Exception as e:
        print(f"‚ùå Hata olu≈ütu: {str(e)}")
        import traceback
        traceback.print_exc()
        return [], {}


def print_results_to_console(all_sections: List[Dict[str, Any]], stats: Dict[str, Any], uploaded_documents: Optional[List[Dict[str, Any]]] = None):
    """
    Sonu√ßlarƒ± konsola yazdƒ±rƒ±r
    
    Args:
        all_sections: T√ºm b√∂l√ºmler ve mevzuatlar
        stats: ƒ∞statistikler
        uploaded_documents: Y√ºkl√º d√∂k√ºmanlar listesi (opsiyonel, stats'ten de alƒ±nabilir)
    """
    print("\n" + "="*80)
    print("üìã BULUNAN MEVZUATLAR (Ahiler Kalkƒ±nma Ajansƒ±)")
    print("="*80)
    
    if not all_sections:
        print("‚ö†Ô∏è Mevzuat bulunamadƒ±!")
        return
    
    print(f"\nüìä Toplam {stats.get('total_sections', 0)} ba≈ülƒ±k altƒ±nda {stats.get('total_items', 0)} mevzuat bulundu")
    print(f"üì¶ API'de {stats.get('uploaded_documents_count', 0)} y√ºkl√º mevzuat var\n")
    
    for section in all_sections:
        section_title = section['section_title']
        items = section['items']
        
        if not items:
            continue
        
        # ƒ∞lgili istatistikleri bul
        section_stat = next(
            (s for s in stats.get('sections_stats', []) if s['section_title'] == section_title),
            {'total': len(items), 'uploaded': 0, 'not_uploaded': len(items)}
        )
        
        print(f"\n{'='*80}")
        print(f"üìÇ {section_title} Toplam:{section_stat['total']}")
        print(f"   ({section_stat['uploaded']} adet - y√ºkl√º ‚úÖ  - {section_stat['not_uploaded']} adet y√ºkl√º deƒüil ‚è≥ )")
        print(f"{'='*80}")
        
        for i, item in enumerate(items, 1):
            # Mevzuatƒ±n y√ºkl√º olup olmadƒ±ƒüƒ±nƒ± kontrol et
            is_uploaded = False
            if uploaded_documents:
                is_uploaded = check_if_document_exists(item['baslik'], uploaded_documents)
                if not is_uploaded and item.get('baslik_original'):
                    is_uploaded = check_if_document_exists(item['baslik_original'], uploaded_documents)
            
            print(f"\n{i}. {item['baslik']}")
            print(f"   üîó {item['link']}")
            
            if is_uploaded:
                print(f"   ‚úÖ MevzuatGPT Y√ºkl√º.")
            else:
                print(f"   ‚è≥ Y√ºkl√º deƒüil")
        
        print()
    
    print("="*80)
    print("‚úÖ Tarama tamamlandƒ±!")
    print("="*80)

