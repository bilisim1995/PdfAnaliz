import streamlit as st
import os
import tempfile
from pathlib import Path
import json
import shutil
from pdf_processor import PDFProcessor
from deepseek_analyzer import DeepSeekAnalyzer
from utils import download_pdf_from_url, create_output_directories, create_pdf_filename

def main():
    st.title("ğŸ“„ PDF RAG BÃ¶lÃ¼mlendirme AracÄ±")
    st.markdown("PDF dosyalarÄ±nÄ±zÄ± RAG iÃ§in optimize edilmiÅŸ bÃ¶lÃ¼mlere ayÄ±rÄ±n ve AI ile analiz edin.")
    
    # Initialize session state
    if 'processing_complete' not in st.session_state:
        st.session_state.processing_complete = False
    if 'json_output' not in st.session_state:
        st.session_state.json_output = ""
    if 'output_dir' not in st.session_state:
        st.session_state.output_dir = ""
    if 'sections' not in st.session_state:
        st.session_state.sections = []
    if 'analysis_complete' not in st.session_state:
        st.session_state.analysis_complete = False
    if 'pdf_path_temp' not in st.session_state:
        st.session_state.pdf_path_temp = ""
    if 'pdf_base_name' not in st.session_state:
        st.session_state.pdf_base_name = ""
    if 'metadata_list' not in st.session_state:
        st.session_state.metadata_list = []
    
    # Sidebar for configuration
    st.sidebar.header("âš™ï¸ Ayarlar")
    
    # DeepSeek API Key
    api_key = os.getenv("DEEPSEEK_API_KEY", "")
    
    # PDF source selection
    st.header("1ï¸âƒ£ PDF KaynaÄŸÄ±nÄ± SeÃ§in")
    source_option = st.radio(
        "PDF kaynaÄŸÄ±nÄ±zÄ± seÃ§in:",
        ["ğŸ’» Bilgisayardan dosya yÃ¼kle", "ğŸŒ URL'den indir"]
    )
    
    pdf_file = None
    pdf_path = None
    uploaded_file = None
    
    if source_option == "ğŸ’» Bilgisayardan dosya yÃ¼kle":
        uploaded_file = st.file_uploader(
            "PDF dosyanÄ±zÄ± seÃ§in:",
            type=['pdf'],
            help="RAG iÃ§in bÃ¶lÃ¼mlendirilecek PDF dosyanÄ±zÄ± yÃ¼kleyin"
        )
        if uploaded_file is not None:
            # Save uploaded file to temporary location
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
                tmp_file.write(uploaded_file.getbuffer())
                pdf_path = tmp_file.name
            st.success(f"âœ… Dosya yÃ¼klendi: {uploaded_file.name}")
    
    elif source_option == "ğŸŒ URL'den indir":
        url_input = st.text_input(
            "PDF URL'sini girin:",
            placeholder="https://example.com/document.pdf",
            help="Ä°ndirilecek PDF dosyasÄ±nÄ±n URL'sini girin"
        )
        
        if url_input:
            if st.button("ğŸ“¥ PDF'i Ä°ndir"):
                with st.spinner("PDF indiriliyor..."):
                    try:
                        pdf_path = download_pdf_from_url(url_input)
                        st.success("âœ… PDF baÅŸarÄ±yla indirildi!")
                    except Exception as e:
                        st.error(f"âŒ PDF indirme hatasÄ±: {str(e)}")
                        pdf_path = None
    
    # Processing section
    if pdf_path:
        st.header("2ï¸âƒ£ PDF Ä°ÅŸleme AyarlarÄ±")
        
        # BÃ¶lÃ¼mleme stratejisi seÃ§imi
        sectioning_mode = st.radio(
            "BÃ¶lÃ¼mleme Stratejisi:",
            ["ğŸ¤– AkÄ±llÄ± BÃ¶lÃ¼mleme (AI bazlÄ±, iÃ§eriÄŸe gÃ¶re)", "ğŸ“ Manuel BÃ¶lÃ¼mleme (sabit sayfa aralÄ±ÄŸÄ±)"],
            help="AkÄ±llÄ± bÃ¶lÃ¼mleme: AI, PDF iÃ§eriÄŸini analiz ederek en mantÄ±klÄ± bÃ¶lÃ¼mleri oluÅŸturur. Manuel bÃ¶lÃ¼mleme: Sayfa sayÄ±sÄ±na gÃ¶re eÅŸit bÃ¶lÃ¼mler oluÅŸturur."
        )
        
        min_pages_per_section = 1
        max_pages_per_section = 30
        
        if sectioning_mode == "ğŸ“ Manuel BÃ¶lÃ¼mleme (sabit sayfa aralÄ±ÄŸÄ±)":
            col1, col2 = st.columns(2)
            with col1:
                min_pages_per_section = st.number_input(
                    "Minimum sayfa/bÃ¶lÃ¼m:",
                    min_value=1,
                    max_value=10,
                    value=3,
                    help="Her bÃ¶lÃ¼mde minimum sayfa sayÄ±sÄ±"
                )
            
            with col2:
                max_pages_per_section = st.number_input(
                    "Maximum sayfa/bÃ¶lÃ¼m:",
                    min_value=2,
                    max_value=30,
                    value=10,
                    help="Her bÃ¶lÃ¼mde maximum sayfa sayÄ±sÄ±"
                )
        else:
            st.info("ğŸ¤– AI, PDF iÃ§eriÄŸini analiz ederek en uygun bÃ¶lÃ¼mleme stratejisini belirleyecek. Bu iÅŸlem biraz daha uzun sÃ¼rebilir.")
            
            # API key kontrolÃ¼
            if not api_key or api_key == "":
                st.warning("âš ï¸ AkÄ±llÄ± bÃ¶lÃ¼mleme iÃ§in DeepSeek API anahtarÄ± gereklidir. LÃ¼tfen Ã¶nce API anahtarÄ±nÄ±zÄ± girin.")
        
        # Process PDF button
        if st.button("ğŸ” PDF'i Analiz Et (1. AdÄ±m)", type="primary"):
            if sectioning_mode == "ğŸ“ Manuel BÃ¶lÃ¼mleme (sabit sayfa aralÄ±ÄŸÄ±)" and min_pages_per_section >= max_pages_per_section:
                st.error("âŒ Minimum sayfa sayÄ±sÄ±, maximum sayfa sayÄ±sÄ±ndan kÃ¼Ã§Ã¼k olmalÄ±dÄ±r!")
            else:
                # PDF dosya adÄ±nÄ± kaydet
                if source_option == "ğŸ’» Bilgisayardan dosya yÃ¼kle" and uploaded_file:
                    st.session_state.pdf_base_name = Path(uploaded_file.name).stem
                else:
                    st.session_state.pdf_base_name = "document"
                
                analyze_and_prepare(pdf_path, api_key, sectioning_mode, min_pages_per_section, max_pages_per_section)
    
    # Analysis results section
    if st.session_state.analysis_complete and not st.session_state.processing_complete:
        st.header("âœ… Analiz TamamlandÄ±!")
        st.success("PDF baÅŸarÄ±yla analiz edildi. AÅŸaÄŸÄ±da oluÅŸturulacak bÃ¶lÃ¼mlerin JSON Ã¶nizlemesini gÃ¶rebilirsiniz.")
        
        # Display JSON output
        st.subheader("ğŸ“Š JSON Ã–nizleme - OluÅŸturulacak BÃ¶lÃ¼mler")
        st.text_area(
            "JSON Ã‡Ä±ktÄ±sÄ±:",
            value=st.session_state.json_output,
            height=400,
            help="PDF parÃ§alandÄ±ÄŸÄ±nda bu yapÄ±da bÃ¶lÃ¼mler oluÅŸturulacak",
            key="json_preview"
        )
        
        # Split PDF button - make it more prominent
        st.divider()
        st.info("ğŸ‘‡ JSON'u inceledikten sonra, PDF'leri bÃ¶lmek iÃ§in aÅŸaÄŸÄ±daki butona tÄ±klayÄ±n:")
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("âœ‚ï¸ PDF'leri Åimdi BÃ¶l (2. AdÄ±m)", type="primary", use_container_width=True, help="JSON'daki sayfa aralÄ±klarÄ±na gÃ¶re PDF'leri hÄ±zlÄ±ca bÃ¶ler ve kaydeder"):
                split_pdf_files()
        
        col4, col5 = st.columns([4, 1])
        with col5:
            if st.button("ğŸ”„ Ä°ptal", help="Analizi iptal et ve baÅŸa dÃ¶n"):
                reset_and_cleanup()
                st.rerun()
    
    # Results section
    if st.session_state.processing_complete:
        st.header("3ï¸âƒ£ Ä°ÅŸlem SonuÃ§larÄ±")
        
        # Display JSON output
        st.subheader("ğŸ“Š BÃ¶lÃ¼m Metadata (JSON)")
        st.text_area(
            "JSON Ã‡Ä±ktÄ±sÄ±:",
            value=st.session_state.json_output,
            height=400,
            help="OluÅŸturulan bÃ¶lÃ¼mler ve metadata bilgileri"
        )
        
        # Download JSON button
        if st.session_state.json_output:
            st.download_button(
                label="ğŸ’¾ JSON'u Ä°ndir",
                data=st.session_state.json_output,
                file_name="pdf_sections_metadata.json",
                mime="application/json"
            )
        
        # Show output directory
        if st.session_state.output_dir:
            st.info(f"ğŸ“ BÃ¶lÃ¼mlenmiÅŸ PDF dosyalarÄ± ÅŸurada kaydedildi: `{st.session_state.output_dir}`")
        
        # Reset button
        st.divider()
        col1, col2 = st.columns([3, 1])
        with col2:
            if st.button("ğŸ—‘ï¸ Verileri SÄ±fÄ±rla", type="secondary", help="TÃ¼m iÅŸlemi sÄ±fÄ±rlar, dosyalarÄ± siler ve uygulamayÄ± yeniden baÅŸlatÄ±r"):
                reset_and_cleanup()
                st.rerun()

def analyze_and_prepare(pdf_path, api_key, sectioning_mode, min_pages, max_pages):
    """Analyze PDF and prepare metadata without splitting files"""
    try:
        # Clean up any existing output directory from previous analysis
        # (Users starting a new analysis should download previous results first if needed)
        if st.session_state.output_dir and os.path.exists(st.session_state.output_dir):
            try:
                shutil.rmtree(st.session_state.output_dir)
            except Exception:
                pass  # Ignore cleanup errors
        
        # Reset state for new analysis
        st.session_state.processing_complete = False
        st.session_state.analysis_complete = False
        st.session_state.json_output = ""
        st.session_state.output_dir = ""
        
        # PDF yolunu kaydet
        st.session_state.pdf_path_temp = pdf_path
        # Create progress bar
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Step 1: Initialize components
        status_text.text("ğŸ”§ BileÅŸenler baÅŸlatÄ±lÄ±yor...")
        progress_bar.progress(10)
        
        processor = PDFProcessor()
        analyzer = DeepSeekAnalyzer(api_key)
        
        # Step 2: Analyze PDF structure
        status_text.text("ğŸ“– PDF yapÄ±sÄ± analiz ediliyor...")
        progress_bar.progress(20)
        
        pdf_info = processor.analyze_pdf_structure(pdf_path)
        st.info(f"ğŸ“„ PDF Bilgisi: {pdf_info['total_pages']} sayfa tespit edildi")
        
        # Step 3: Create optimal sections
        if sectioning_mode == "ğŸ¤– AkÄ±llÄ± BÃ¶lÃ¼mleme (AI bazlÄ±, iÃ§eriÄŸe gÃ¶re)":
            status_text.text("ğŸ¤– AI ile iÃ§erik bazlÄ± bÃ¶lÃ¼mler oluÅŸturuluyor...")
            progress_bar.progress(30)
            
            try:
                sections = processor.create_intelligent_sections(
                    pdf_path, 
                    pdf_info['total_pages'], 
                    analyzer
                )
                
                # BÃ¶lÃ¼m nedenlerini gÃ¶ster
                st.success(f"ğŸ¤– AI {len(sections)} anlamlÄ± bÃ¶lÃ¼m oluÅŸturdu")
                with st.expander("ğŸ“‹ BÃ¶lÃ¼mleme DetaylarÄ±"):
                    for i, section in enumerate(sections):
                        st.write(f"**BÃ¶lÃ¼m {i+1}:** Sayfa {section['start_page']}-{section['end_page']}")
                        if section.get('reason'):
                            st.write(f"   â””â”€ *{section['reason']}*")
            except Exception as e:
                st.warning(f"âš ï¸ AI bÃ¶lÃ¼mleme baÅŸarÄ±sÄ±z oldu: {str(e)}")
                st.info("ğŸ“ Otomatik olarak manuel bÃ¶lÃ¼mleme moduna geÃ§iliyor...")
                
                # Fallback: Manuel bÃ¶lÃ¼mleme
                sections = processor.create_optimal_sections(
                    pdf_path, 
                    pdf_info['total_pages'], 
                    3,  # Default min pages
                    10  # Default max pages
                )
        else:
            status_text.text("âœ‚ï¸ Manuel bÃ¶lÃ¼mler oluÅŸturuluyor...")
            
            sections = processor.create_optimal_sections(
                pdf_path, 
                pdf_info['total_pages'], 
                min_pages, 
                max_pages
            )
        
        # Session state'e sections'Ä± kaydet
        st.session_state.sections = sections
        
        progress_bar.progress(40)
        
        if sectioning_mode != "ğŸ¤– AkÄ±llÄ± BÃ¶lÃ¼mleme (AI bazlÄ±, iÃ§eriÄŸe gÃ¶re)":
            st.info(f"ğŸ“ {len(sections)} bÃ¶lÃ¼m oluÅŸturuldu")
        
        # Step 4: Analyze content and prepare metadata (WITHOUT creating PDF files)
        status_text.text("ğŸ¤– AI ile iÃ§erik analiz ediliyor...")
        progress_bar.progress(60)
        
        metadata_list = []
        
        for i, section in enumerate(sections):
            # Extract text for analysis
            section_text = processor.extract_text_from_pages(
                pdf_path, 
                section['start_page'], 
                section['end_page']
            )
            
            # Analyze with DeepSeek
            if section_text.strip():  # Only analyze if there's actual text
                analysis = analyzer.analyze_section_content(section_text)
                
                # API hata kontrolÃ¼
                if 'API Analiz HatasÄ±' in analysis.get('title', ''):
                    st.warning(f"âš ï¸ BÃ¶lÃ¼m {i + 1} iÃ§in AI analizi baÅŸarÄ±sÄ±z oldu. Hata: {analysis.get('description', '')}")
                
                title = analysis.get('title', f'BÃ¶lÃ¼m {i + 1}')
                
                # Dosya adÄ±nÄ± oluÅŸtur (TÃ¼rkÃ§e karaktersiz)
                output_filename = create_pdf_filename(
                    st.session_state.pdf_base_name,
                    i + 1,
                    section['start_page'],
                    section['end_page'],
                    title
                )
                
                metadata = {
                    "output_filename": output_filename,
                    "start_page": section['start_page'],
                    "end_page": section['end_page'],
                    "title": title,
                    "description": analysis.get('description', 'Bu bÃ¶lÃ¼m iÃ§in aÃ§Ä±klama oluÅŸturulamadÄ±.'),
                    "keywords": analysis.get('keywords', f'bÃ¶lÃ¼m {i + 1}')
                }
            else:
                # Fallback for sections with no extractable text
                output_filename = create_pdf_filename(
                    st.session_state.pdf_base_name,
                    i + 1,
                    section['start_page'],
                    section['end_page'],
                    ""
                )
                
                metadata = {
                    "output_filename": output_filename,
                    "start_page": section['start_page'],
                    "end_page": section['end_page'],
                    "title": f"BÃ¶lÃ¼m {i + 1}",
                    "description": "Bu bÃ¶lÃ¼mde metin iÃ§eriÄŸi tespit edilemedi. GÃ¶rsel iÃ§erik veya tablo bulunuyor olabilir.",
                    "keywords": f"bÃ¶lÃ¼m {i + 1},gÃ¶rsel iÃ§erik"
                }
            
            metadata_list.append(metadata)
            
            # Update progress
            section_progress = 60 + (i + 1) / len(sections) * 25
            progress_bar.progress(int(section_progress))
            status_text.text(f"ğŸ¤– BÃ¶lÃ¼m {i + 1}/{len(sections)} analiz edildi...")
        
        # Save metadata list to session state
        st.session_state.metadata_list = metadata_list
        
        # Step 5: Generate final JSON
        status_text.text("ğŸ“„ JSON Ã§Ä±ktÄ±sÄ± oluÅŸturuluyor...")
        progress_bar.progress(90)
        
        final_json = {
            "pdf_sections": metadata_list
        }
        
        json_output = json.dumps(final_json, ensure_ascii=False, indent=2)
        st.session_state.json_output = json_output
        
        # Complete
        progress_bar.progress(100)
        status_text.text("âœ… Analiz tamamlandÄ±!")
        st.session_state.analysis_complete = True
        
        st.success(f"ğŸ‰ Analiz baÅŸarÄ±yla tamamlandÄ±! {len(sections)} bÃ¶lÃ¼m iÃ§in metadata oluÅŸturuldu.")
        st.info("ğŸ‘‡ AÅŸaÄŸÄ±da JSON Ã§Ä±ktÄ±sÄ±nÄ± inceleyebilir ve PDF'leri parÃ§alayabilirsiniz.")
        
    except Exception as e:
        st.error(f"âŒ Ä°ÅŸlem sÄ±rasÄ±nda hata oluÅŸtu: {str(e)}")
        st.exception(e)

def split_pdf_files():
    """Split PDF files according to prepared metadata"""
    try:
        # Create progress bar
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Get data from session state
        pdf_path = st.session_state.pdf_path_temp
        metadata_list = st.session_state.metadata_list
        sections = st.session_state.sections
        
        # Step 1: Create output directories (only if not already created)
        status_text.text("ğŸ“ Ã‡Ä±ktÄ± klasÃ¶rleri hazÄ±rlanÄ±yor...")
        progress_bar.progress(10)
        
        if not st.session_state.output_dir or not os.path.exists(st.session_state.output_dir):
            output_dir = create_output_directories()
            st.session_state.output_dir = output_dir
        else:
            output_dir = st.session_state.output_dir
        
        # Step 2: Split PDF files
        status_text.text("âœ‚ï¸ PDF dosyalarÄ± parÃ§alanÄ±yor...")
        progress_bar.progress(30)
        
        processor = PDFProcessor()
        
        for i, (section, metadata) in enumerate(zip(sections, metadata_list)):
            # Create section PDF with the specified filename
            output_path = Path(output_dir) / metadata['output_filename']
            
            # Create PDF using processor
            with open(pdf_path, 'rb') as source_file:
                import pypdf
                reader = pypdf.PdfReader(source_file)
                writer = pypdf.PdfWriter()
                
                # Add pages to writer
                for page_num in range(section['start_page'] - 1, section['end_page']):
                    if page_num < len(reader.pages):
                        writer.add_page(reader.pages[page_num])
                
                # Save PDF
                with open(output_path, 'wb') as output_file:
                    writer.write(output_file)
            
            # Update progress
            file_progress = 30 + (i + 1) / len(sections) * 60
            progress_bar.progress(int(file_progress))
            status_text.text(f"âœ‚ï¸ BÃ¶lÃ¼m {i + 1}/{len(sections)} oluÅŸturuldu...")
        
        # Step 3: Save JSON to file
        status_text.text("ğŸ’¾ JSON dosyasÄ± kaydediliyor...")
        progress_bar.progress(95)
        
        json_path = Path(output_dir) / "pdf_sections_metadata.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            f.write(st.session_state.json_output)
        
        # Complete
        progress_bar.progress(100)
        status_text.text("âœ… PDF parÃ§alama tamamlandÄ±!")
        st.session_state.processing_complete = True
        st.session_state.analysis_complete = False  # Analiz bÃ¶lÃ¼mÃ¼nÃ¼ gizle
        
        st.success(f"ğŸ‰ {len(sections)} PDF dosyasÄ± baÅŸarÄ±yla oluÅŸturuldu!")
        st.balloons()
        
    except Exception as e:
        st.error(f"âŒ PDF parÃ§alama sÄ±rasÄ±nda hata oluÅŸtu: {str(e)}")
        st.exception(e)

def reset_and_cleanup():
    """Reset all session state and clean up files"""
    try:
        # DosyalarÄ± ve klasÃ¶rÃ¼ sil
        if st.session_state.output_dir and os.path.exists(st.session_state.output_dir):
            shutil.rmtree(st.session_state.output_dir)
            print(f"KlasÃ¶r silindi: {st.session_state.output_dir}")
    except Exception as e:
        print(f"KlasÃ¶r silme hatasÄ±: {str(e)}")
    
    # Session state'i temizle
    st.session_state.processing_complete = False
    st.session_state.json_output = ""
    st.session_state.output_dir = ""
    st.session_state.sections = []
    st.session_state.analysis_complete = False
    st.session_state.pdf_path_temp = ""
    st.session_state.pdf_base_name = ""
    st.session_state.metadata_list = []

if __name__ == "__main__":
    main()
