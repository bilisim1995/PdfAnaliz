import streamlit as st
import os
import tempfile
from pathlib import Path
import json
from pdf_processor import PDFProcessor
from deepseek_analyzer import DeepSeekAnalyzer
from utils import download_pdf_from_url, create_output_directories

def main():
    st.title("ğŸ“„ PDF RAG BÃ¶lÃ¼mlendirme AracÄ±")
    st.markdown("PDF dosyalarÄ±nÄ±zÄ± RAG iÃ§in optimize edilmiÅŸ bÃ¶lÃ¼mlere ayÄ±rÄ±n ve AI ile analiz edin.")
    
    # Initialize session state
    if 'processing_complete' not in st.session_state:
        st.session_state.processing_complete = False
    if 'json_output' not in st.session_state:
        st.session_state.json_output = ""
    if 'output_dir' not in st.session_state:
        st.session_state.output_dir = ""
    
    # Sidebar for configuration
    st.sidebar.header("âš™ï¸ Ayarlar")
    
    # DeepSeek API Key
    api_key = os.getenv("DEEPSEEK_API_KEY", "sk-8c15dc40c6b44cde9880f7a47b4be333")
    
    # PDF source selection
    st.header("1ï¸âƒ£ PDF KaynaÄŸÄ±nÄ± SeÃ§in")
    source_option = st.radio(
        "PDF kaynaÄŸÄ±nÄ±zÄ± seÃ§in:",
        ["ğŸ’» Bilgisayardan dosya yÃ¼kle", "ğŸŒ URL'den indir"]
    )
    
    pdf_file = None
    pdf_path = None
    
    if source_option == "ğŸ’» Bilgisayardan dosya yÃ¼kle":
        uploaded_file = st.file_uploader(
            "PDF dosyanÄ±zÄ± seÃ§in:",
            type=['pdf'],
            help="RAG iÃ§in bÃ¶lÃ¼mlendirilecek PDF dosyanÄ±zÄ± yÃ¼kleyin"
        )
        if uploaded_file is not None:
            # Save uploaded file to temporary location
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
                tmp_file.write(uploaded_file.getbuffer())
                pdf_path = tmp_file.name
            st.success(f"âœ… Dosya yÃ¼klendi: {uploaded_file.name}")
    
    elif source_option == "ğŸŒ URL'den indir":
        url_input = st.text_input(
            "PDF URL'sini girin:",
            placeholder="https://example.com/document.pdf",
            help="Ä°ndirilecek PDF dosyasÄ±nÄ±n URL'sini girin"
        )
        
        if url_input:
            if st.button("ğŸ“¥ PDF'i Ä°ndir"):
                with st.spinner("PDF indiriliyor..."):
                    try:
                        pdf_path = download_pdf_from_url(url_input)
                        st.success("âœ… PDF baÅŸarÄ±yla indirildi!")
                    except Exception as e:
                        st.error(f"âŒ PDF indirme hatasÄ±: {str(e)}")
                        pdf_path = None
    
    # Processing section
    if pdf_path:
        st.header("2ï¸âƒ£ PDF Ä°ÅŸleme AyarlarÄ±")
        
        col1, col2 = st.columns(2)
        with col1:
            min_pages_per_section = st.number_input(
                "Minimum sayfa/bÃ¶lÃ¼m:",
                min_value=1,
                max_value=10,
                value=1,
                help="Her bÃ¶lÃ¼mde minimum sayfa sayÄ±sÄ±"
            )
        
        with col2:
            max_pages_per_section = st.number_input(
                "Maximum sayfa/bÃ¶lÃ¼m:",
                min_value=2,
                max_value=30,
                value=5,
                help="Her bÃ¶lÃ¼mde maximum sayfa sayÄ±sÄ±"
            )
        
        # Process PDF button
        if st.button("ğŸš€ PDF'i Ä°ÅŸle ve Analiz Et", type="primary"):
            if min_pages_per_section >= max_pages_per_section:
                st.error("âŒ Minimum sayfa sayÄ±sÄ±, maximum sayfa sayÄ±sÄ±ndan kÃ¼Ã§Ã¼k olmalÄ±dÄ±r!")
            else:
                process_pdf(pdf_path, api_key, min_pages_per_section, max_pages_per_section)
    
    # Results section
    if st.session_state.processing_complete:
        st.header("3ï¸âƒ£ Ä°ÅŸlem SonuÃ§larÄ±")
        
        # Display JSON output
        st.subheader("ğŸ“Š BÃ¶lÃ¼m Metadata (JSON)")
        st.text_area(
            "JSON Ã‡Ä±ktÄ±sÄ±:",
            value=st.session_state.json_output,
            height=400,
            help="OluÅŸturulan bÃ¶lÃ¼mler ve metadata bilgileri"
        )
        
        # Download JSON button
        if st.session_state.json_output:
            st.download_button(
                label="ğŸ’¾ JSON'u Ä°ndir",
                data=st.session_state.json_output,
                file_name="pdf_sections_metadata.json",
                mime="application/json"
            )
        
        # Show output directory
        if st.session_state.output_dir:
            st.info(f"ğŸ“ BÃ¶lÃ¼mlenmiÅŸ PDF dosyalarÄ± ÅŸurada kaydedildi: `{st.session_state.output_dir}`")
        
        # Reset button
        if st.button("ğŸ”„ Yeni Ä°ÅŸlem"):
            reset_session_state()
            st.rerun()

def process_pdf(pdf_path, api_key, min_pages, max_pages):
    """Process PDF file and create sections"""
    try:
        # Create progress bar
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Step 1: Initialize components
        status_text.text("ğŸ”§ BileÅŸenler baÅŸlatÄ±lÄ±yor...")
        progress_bar.progress(10)
        
        processor = PDFProcessor()
        analyzer = DeepSeekAnalyzer(api_key)
        
        # Step 2: Create output directories
        status_text.text("ğŸ“ Ã‡Ä±ktÄ± klasÃ¶rleri oluÅŸturuluyor...")
        progress_bar.progress(20)
        
        output_dir = create_output_directories()
        st.session_state.output_dir = output_dir
        
        # Step 3: Analyze PDF structure
        status_text.text("ğŸ“– PDF yapÄ±sÄ± analiz ediliyor...")
        progress_bar.progress(30)
        
        pdf_info = processor.analyze_pdf_structure(pdf_path)
        st.info(f"ğŸ“„ PDF Bilgisi: {pdf_info['total_pages']} sayfa tespit edildi")
        
        # Step 4: Create optimal sections
        status_text.text("âœ‚ï¸ Optimal bÃ¶lÃ¼mler oluÅŸturuluyor...")
        progress_bar.progress(50)
        
        sections = processor.create_optimal_sections(
            pdf_path, 
            pdf_info['total_pages'], 
            min_pages, 
            max_pages
        )
        
        st.info(f"ğŸ“ {len(sections)} bÃ¶lÃ¼m oluÅŸturuldu")
        
        # Step 5: Generate section files and analyze content
        status_text.text("ğŸ¤– AI ile iÃ§erik analiz ediliyor...")
        progress_bar.progress(70)
        
        metadata_list = []
        
        for i, section in enumerate(sections):
            # Create section PDF
            section_path = processor.create_section_pdf(
                pdf_path, 
                section['start_page'], 
                section['end_page'], 
                output_dir, 
                i + 1
            )
            
            # Extract text for analysis
            section_text = processor.extract_text_from_pages(
                pdf_path, 
                section['start_page'], 
                section['end_page']
            )
            
            # Analyze with DeepSeek
            if section_text.strip():  # Only analyze if there's actual text
                analysis = analyzer.analyze_section_content(section_text)
                
                metadata = {
                    "output_filename": Path(section_path).name,
                    "start_page": section['start_page'],
                    "end_page": section['end_page'],
                    "title": analysis.get('title', f'BÃ¶lÃ¼m {i + 1}'),
                    "description": analysis.get('description', 'Bu bÃ¶lÃ¼m iÃ§in aÃ§Ä±klama oluÅŸturulamadÄ±.'),
                    "keywords": analysis.get('keywords', f'bÃ¶lÃ¼m_{i + 1}')
                }
            else:
                # Fallback for sections with no extractable text
                metadata = {
                    "output_filename": Path(section_path).name,
                    "start_page": section['start_page'],
                    "end_page": section['end_page'],
                    "title": f"BÃ¶lÃ¼m {i + 1}",
                    "description": "Bu bÃ¶lÃ¼mde metin iÃ§eriÄŸi tespit edilemedi. GÃ¶rsel iÃ§erik veya tablo bulunuyor olabilir.",
                    "keywords": f"bÃ¶lÃ¼m_{i + 1},gÃ¶rsel_iÃ§erik"
                }
            
            metadata_list.append(metadata)
            
            # Update progress
            section_progress = 70 + (i + 1) / len(sections) * 20
            progress_bar.progress(int(section_progress))
            status_text.text(f"ğŸ¤– BÃ¶lÃ¼m {i + 1}/{len(sections)} analiz edildi...")
        
        # Step 6: Generate final JSON
        status_text.text("ğŸ“„ JSON Ã§Ä±ktÄ±sÄ± oluÅŸturuluyor...")
        progress_bar.progress(95)
        
        final_json = {
            "pdf_sections": metadata_list
        }
        
        json_output = json.dumps(final_json, ensure_ascii=False, indent=2)
        st.session_state.json_output = json_output
        
        # Save JSON to file
        json_path = Path(output_dir) / "pdf_sections_metadata.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            f.write(json_output)
        
        # Complete
        progress_bar.progress(100)
        status_text.text("âœ… Ä°ÅŸlem tamamlandÄ±!")
        st.session_state.processing_complete = True
        
        st.success(f"ğŸ‰ Ä°ÅŸlem baÅŸarÄ±yla tamamlandÄ±! {len(sections)} bÃ¶lÃ¼m oluÅŸturuldu.")
        
    except Exception as e:
        st.error(f"âŒ Ä°ÅŸlem sÄ±rasÄ±nda hata oluÅŸtu: {str(e)}")
        st.exception(e)

def reset_session_state():
    """Reset all session state variables"""
    st.session_state.processing_complete = False
    st.session_state.json_output = ""
    st.session_state.output_dir = ""

if __name__ == "__main__":
    main()
